{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0448e2-3c87-45d3-858e-6f0853e6e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING PHASE ===\n",
      "Training Data:\n",
      "   study_hours  attendance  previous_grade result\n",
      "0            2          60              70   Fail\n",
      "1            8          95              85   Pass\n",
      "2            5          80              78   Pass\n",
      "3            1          40              45   Fail\n",
      "4            9          98              92   Pass\n",
      "5            3          65              68   Fail\n",
      "6            7          90              88   Pass\n",
      "7            4          75              72   Pass\n",
      "8            6          85              82   Pass\n",
      "9           10         100              95   Pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Implementation - From Training to Production\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # For saving/loading models\n",
    "import numpy as np\n",
    "\n",
    "# ========== STEP 1: TRAINING PHASE ==========\n",
    "print(\"=== TRAINING PHASE ===\")\n",
    "\n",
    "# Sample training data - Student performance prediction\n",
    "data = {\n",
    "    'study_hours': [2, 8, 5, 1, 9, 3, 7, 4, 6, 10],\n",
    "    'attendance': [60, 95, 80, 40, 98, 65, 90, 75, 85, 100],\n",
    "    'previous_grade': [70, 85, 78, 45, 92, 68, 88, 72, 82, 95],\n",
    "    'result': ['Fail', 'Pass', 'Pass', 'Fail', 'Pass', 'Fail', 'Pass', 'Pass', 'Pass', 'Pass']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Training Data:\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9870f41d-ace8-41fd-b1f2-85d90e6e787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = df[['study_hours', 'attendance', 'previous_grade']]\n",
    "y = df['result']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = dt_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204c2b0-9a3e-48e2-8410-91732970fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING PHASE ===\n",
      "Training Data:\n",
      "   study_hours  attendance  previous_grade result\n",
      "0            2          60              70   Fail\n",
      "1            8          95              85   Pass\n",
      "2            5          80              78   Pass\n",
      "3            1          40              45   Fail\n",
      "4            9          98              92   Pass\n",
      "5            3          65              68   Fail\n",
      "6            7          90              88   Pass\n",
      "7            4          75              72   Pass\n",
      "8            6          85              82   Pass\n",
      "9           10         100              95   Pass\n",
      "\n",
      "Model Accuracy: 1.00\n",
      "\n",
      "=== SAVING MODEL FOR PRODUCTION ===\n",
      "✅ Model saved as 'student_performance_model.pkl'\n",
      "\n",
      "=== PRODUCTION PHASE - PREDICTING NEW DATA ===\n",
      "✅ Model loaded successfully\n",
      "\n",
      "--- Scenario 1: Single New Student ---\n",
      "New Student Data:\n",
      "   study_hours  attendance  previous_grade\n",
      "0            6          88              79\n",
      "Prediction: Pass\n",
      "Probability - Fail: 0.000, Pass: 1.000\n",
      "\n",
      "--- Scenario 2: Batch Processing ---\n",
      "New Batch Data:\n",
      "   study_hours  attendance  previous_grade\n",
      "0            3          65              55\n",
      "1            9          96              91\n",
      "2            5          82              76\n",
      "3            7          89              84\n",
      "Batch Predictions:\n",
      "Student 1: Fail (Pass probability: 0.000)\n",
      "Student 2: Pass (Pass probability: 1.000)\n",
      "Student 3: Pass (Pass probability: 1.000)\n",
      "Student 4: Pass (Pass probability: 1.000)\n",
      "\n",
      "--- Scenario 3: Real-time API Function ---\n",
      "API Function Results:\n",
      "Student A: {'prediction': 'Pass', 'pass_probability': 1.0, 'confidence': 'High'}\n",
      "Student B: {'prediction': 'Fail', 'pass_probability': 0.0, 'confidence': 'High'}\n",
      "\n",
      "--- Scenario 4: Production with Data Validation ---\n",
      "Robust Prediction Result:\n",
      "{'success': True, 'results': [{'student_id': 1, 'prediction': 'Pass', 'pass_probability': 1.0, 'fail_probability': 0.0}, {'student_id': 2, 'prediction': 'Fail', 'pass_probability': 0.0, 'fail_probability': 1.0}]}\n",
      "\n",
      "=== IMPLEMENTATION SUMMARY ===\n",
      "1. Train model on historical data\n",
      "2. Save model using joblib.dump()\n",
      "3. Load model in production using joblib.load()\n",
      "4. Create prediction functions for different scenarios:\n",
      "   - Single predictions\n",
      "   - Batch processing\n",
      "   - API endpoints\n",
      "   - Error handling & validation\n",
      "5. Model makes predictions on new data with same features\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 2: SAVE THE MODEL ==========\n",
    "print(\"=== SAVING MODEL FOR PRODUCTION ===\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(dt_model, 'student_performance_model.pkl')\n",
    "print(\"✅ Model saved as 'student_performance_model.pkl'\")\n",
    "print()\n",
    "\n",
    "# ========== STEP 3: PRODUCTION PHASE - NEW DATA ARRIVES ==========\n",
    "print(\"=== PRODUCTION PHASE - PREDICTING NEW DATA ===\")\n",
    "\n",
    "# Load the saved model (this would be done in production environment)\n",
    "loaded_model = joblib.load('student_performance_model.pkl')\n",
    "print(\"✅ Model loaded successfully\")\n",
    "print()\n",
    "\n",
    "# ========== SCENARIO 1: Single New Student ==========\n",
    "print(\"--- Scenario 1: Single New Student ---\")\n",
    "\n",
    "# New student data arrives\n",
    "new_student = {\n",
    "    'study_hours': 6,\n",
    "    'attendance': 88,\n",
    "    'previous_grade': 79\n",
    "}\n",
    "\n",
    "# Convert to DataFrame (same format as training)\n",
    "new_student_df = pd.DataFrame([new_student])\n",
    "print(\"New Student Data:\")\n",
    "print(new_student_df)\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(new_student_df)\n",
    "prediction_proba = loaded_model.predict_proba(new_student_df)\n",
    "\n",
    "print(f\"Prediction: {prediction[0]}\")\n",
    "print(f\"Probability - Fail: {prediction_proba[0][0]:.3f}, Pass: {prediction_proba[0][1]:.3f}\")\n",
    "print()\n",
    "\n",
    "# ========== SCENARIO 2: Batch of New Students ==========\n",
    "print(\"--- Scenario 2: Batch Processing ---\")\n",
    "\n",
    "# Multiple new students arrive\n",
    "new_batch = {\n",
    "    'study_hours': [3, 9, 5, 7],\n",
    "    'attendance': [65, 96, 82, 89],\n",
    "    'previous_grade': [55, 91, 76, 84]\n",
    "}\n",
    "\n",
    "new_batch_df = pd.DataFrame(new_batch)\n",
    "print(\"New Batch Data:\")\n",
    "print(new_batch_df)\n",
    "\n",
    "# Batch predictions\n",
    "batch_predictions = loaded_model.predict(new_batch_df)\n",
    "batch_probabilities = loaded_model.predict_proba(new_batch_df)\n",
    "\n",
    "print(\"Batch Predictions:\")\n",
    "for i, (pred, prob) in enumerate(zip(batch_predictions, batch_probabilities)):\n",
    "    print(f\"Student {i+1}: {pred} (Pass probability: {prob[1]:.3f})\")\n",
    "print()\n",
    "\n",
    "# ========== SCENARIO 3: REAL-TIME API FUNCTION ==========\n",
    "print(\"--- Scenario 3: Real-time API Function ---\")\n",
    "\n",
    "def predict_student_performance(study_hours, attendance, previous_grade):\n",
    "    \"\"\"\n",
    "    Function that would be called by an API endpoint\n",
    "    \"\"\"\n",
    "    # Load model (in real API, you'd load this once at startup)\n",
    "    model = joblib.load('student_performance_model.pkl')\n",
    "    \n",
    "    # Prepare input data\n",
    "    input_data = pd.DataFrame({\n",
    "        'study_hours': [study_hours],\n",
    "        'attendance': [attendance], \n",
    "        'previous_grade': [previous_grade]\n",
    "    })\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    probability = model.predict_proba(input_data)[0]\n",
    "    \n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'pass_probability': round(probability[1], 3),\n",
    "        'confidence': 'High' if max(probability) > 0.8 else 'Medium' if max(probability) > 0.6 else 'Low'\n",
    "    }\n",
    "\n",
    "# Test the API function\n",
    "result1 = predict_student_performance(study_hours=8, attendance=92, previous_grade=85)\n",
    "result2 = predict_student_performance(study_hours=2, attendance=45, previous_grade=50)\n",
    "\n",
    "print(\"API Function Results:\")\n",
    "print(f\"Student A: {result1}\")\n",
    "print(f\"Student B: {result2}\")\n",
    "print()\n",
    "\n",
    "# ========== SCENARIO 4: HANDLING NEW DATA WITH VALIDATION ==========\n",
    "print(\"--- Scenario 4: Production with Data Validation ---\")\n",
    "\n",
    "def robust_prediction(input_data):\n",
    "    \"\"\"\n",
    "    Production-ready function with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model\n",
    "        model = joblib.load('student_performance_model.pkl')\n",
    "        \n",
    "        # Validate input data\n",
    "        required_columns = ['study_hours', 'attendance', 'previous_grade']\n",
    "        \n",
    "        if not all(col in input_data.columns for col in required_columns):\n",
    "            return {\"error\": f\"Missing required columns: {required_columns}\"}\n",
    "        \n",
    "        # Basic data validation\n",
    "        if (input_data['study_hours'] < 0).any() or (input_data['study_hours'] > 12).any():\n",
    "            return {\"error\": \"Study hours must be between 0-12\"}\n",
    "        \n",
    "        if (input_data['attendance'] < 0).any() or (input_data['attendance'] > 100).any():\n",
    "            return {\"error\": \"Attendance must be between 0-100\"}\n",
    "            \n",
    "        # Make prediction\n",
    "        predictions = model.predict(input_data)\n",
    "        probabilities = model.predict_proba(input_data)\n",
    "        \n",
    "        results = []\n",
    "        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "            results.append({\n",
    "                'student_id': i+1,\n",
    "                'prediction': pred,\n",
    "                'pass_probability': round(prob[1], 3),\n",
    "                'fail_probability': round(prob[0], 3)\n",
    "            })\n",
    "        \n",
    "        return {\"success\": True, \"results\": results}\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": \"Model file not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\"}\n",
    "\n",
    "# Test robust function\n",
    "test_data = pd.DataFrame({\n",
    "    'study_hours': [7, 3],\n",
    "    'attendance': [85, 60],\n",
    "    'previous_grade': [80, 65]\n",
    "})\n",
    "\n",
    "robust_result = robust_prediction(test_data)\n",
    "print(\"Robust Prediction Result:\")\n",
    "print(robust_result)\n",
    "\n",
    "print(\"\\n=== IMPLEMENTATION SUMMARY ===\")\n",
    "print(\"1. Train model on historical data\")\n",
    "print(\"2. Save model using joblib.dump()\")  \n",
    "print(\"3. Load model in production using joblib.load()\")\n",
    "print(\"4. Create prediction functions for different scenarios:\")\n",
    "print(\"   - Single predictions\")\n",
    "print(\"   - Batch processing\") \n",
    "print(\"   - API endpoints\")\n",
    "print(\"   - Error handling & validation\")\n",
    "print(\"5. Model makes predictions on new data with same features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b78d56-072c-435f-8e56-abbb41249be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
